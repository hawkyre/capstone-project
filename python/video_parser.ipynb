{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31da62b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install deepgram-sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e77547c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from deepgram import Deepgram\n",
    "import json\n",
    "import re\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from ImagesEmotionLucas.scripts.frames_processing import ImageToEmotion\n",
    "from plotter import Plotter\n",
    "from text_to_emotion import TextToEmotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40987295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The API key we created in step 3\n",
    "DEEPGRAM_API_KEY = '4d7ae42383509c771f0de389b766ffbb2f794ca8'\n",
    "\n",
    "# Replace with your file path and audio mimetype\n",
    "MIMETYPE = 'audio/mp4'\n",
    "\n",
    "def video_to_text(video_path):\n",
    "    # Initializes the Deepgram SDK\n",
    "    dg_client = Deepgram(DEEPGRAM_API_KEY)\n",
    "    \n",
    "    with open(video_path, 'rb') as audio:\n",
    "        source = {'buffer': audio, 'mimetype': MIMETYPE}\n",
    "        options = { \"punctuate\": True, \"model\": \"general\", \"language\": \"en-US\", \"tier\": \"enhanced\", \"diarize\": True}\n",
    "    \n",
    "        print('Requesting transcript...')\n",
    "        print('Your file may take up to a couple minutes to process.')\n",
    "        print('While you wait, did you know that Deepgram accepts over 40 audio file formats? Even MP4s.')\n",
    "        print('To learn more about customizing your transcripts check out developers.deepgram.com')\n",
    "    \n",
    "        response = dg_client.transcription.sync_prerecorded(source, options)\n",
    "        # print(json.dumps(response, indent=4))\n",
    "        print('Transcript obtained.')\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7befa7b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# video_to_text(r'C:\\Users\\hawky\\university\\IA\\final\\capstone-project\\sample_videos\\click_cut.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7178a011",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_regex = re.compile(r'((?<=[.?!]\")|((?<=[.?!])(?!\")))\\s*')\n",
    "\n",
    "def separate_sentences(text):\n",
    "    sentences = [x for x in re.split(sentence_regex, text) if len(x) > 0]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a68f38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestamp_sentences(sentences, words):\n",
    "    word_index = 0\n",
    "    sentences_timed = []\n",
    "    for i in range(len(sentences)):\n",
    "        sent = sentences[i]\n",
    "        sentence_word_length = len(sent.split())\n",
    "        word_range = words[word_index : (word_index+sentence_word_length)]\n",
    "        time_start = word_range[0]['start']\n",
    "        time_end = word_range[-1]['end']\n",
    "        sentences_timed.append((sent, time_start, time_end))\n",
    "        word_index += sentence_word_length\n",
    "    \n",
    "    return sentences_timed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54325bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_sentences(sentences, window_size=10):\n",
    "    padding_start = [('', sentences[0][1], sentences[0][1])] * (window_size-1)\n",
    "    padding_end = [('', sentences[-1][2], sentences[-1][2])] * (window_size-1)\n",
    "    sentences = padding_start + sentences + padding_end\n",
    "    longer_sentences = []\n",
    "\n",
    "    for i in range(len(sentences) - window_size + 1):\n",
    "        sent_group = sentences[i:i + window_size]\n",
    "        sentence = ' '.join([x[0] for x in sent_group])\n",
    "        sentence_start = sent_group[0][1]\n",
    "        sentence_end = sent_group[-1][2]\n",
    "        longer_sentences.append((sentence.strip(), sentence_start, sentence_end))\n",
    "\n",
    "    return longer_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa19de63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_transcript(json):\n",
    "    transcript_data = json['results']['channels'][0]['alternatives'][0]\n",
    "    transcript = transcript_data['transcript']\n",
    "    words = transcript_data['words']\n",
    "    sentences = separate_sentences(transcript)\n",
    "    sentences = timestamp_sentences(sentences, words)\n",
    "    sentences = group_sentences(sentences)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4987eb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_images_from_video(video_path, images_per_second = 0.8):\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "    if fps < 0.1:\n",
    "        print(\"VIDEO NOT FOUND\")\n",
    "        return\n",
    "    \n",
    "    frames_to_skip = fps / images_per_second\n",
    "    images = []\n",
    "    stop = False\n",
    "    current_frame = 0.0\n",
    "    while not stop:\n",
    "        video.set(cv2.CAP_PROP_POS_FRAMES, math.floor(current_frame))\n",
    "        ret, img = video.read()\n",
    "        if ret:\n",
    "            timestamp = current_frame / fps\n",
    "            images.append((img, timestamp))\n",
    "            current_frame += frames_to_skip\n",
    "        else:\n",
    "            stop = True\n",
    "    \n",
    "    return images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883a156a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from plotter import Plotter\n",
    "# from text_to_emotion import TextToEmotion\n",
    "\n",
    "# tte = TextToEmotion()\n",
    "\n",
    "# sentences = process_transcript(json_doc)\n",
    "# text_emotion_scores = tte.sentence_group_to_stats(sentences)\n",
    "\n",
    "# Plotter.plot_data([], text_emotion_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff734235",
   "metadata": {},
   "outputs": [],
   "source": [
    "ite = ImageToEmotion()\n",
    "\n",
    "def parse_images(images):\n",
    "    images_parsed = []\n",
    "    index = 0\n",
    "    for img, timestamp in images:\n",
    "        scores, max_label = ite.process_image(img)\n",
    "        images_parsed.append(\n",
    "                    {'x': timestamp, 'y': scores, 'image_index': index})\n",
    "        print(\"Parsed image {}\".format(index))\n",
    "        index += 1\n",
    "    \n",
    "    return images_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44a6fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('sample_response.json')\n",
    "json_doc = json.load(f)\n",
    "\n",
    "def parse_video(video_path):\n",
    "    images = extract_images_from_video(video_path)\n",
    "    parsed_images = parse_images(images)\n",
    "    \n",
    "    tte = TextToEmotion()\n",
    "    json_transcript = video_to_text(video_path)\n",
    "    # json_transcript = json_doc\n",
    "    sentences = process_transcript(json_transcript)\n",
    "    text_emotion_scores = tte.sentence_group_to_stats(sentences)\n",
    "\n",
    "    Plotter.plot_data(parsed_images, text_emotion_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e19f3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_path = r'C:\\Users\\hawky\\university\\IA\\final\\capstone-project\\sample_videos\\smash_drama.mp4'\n",
    "parse_video(vid_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7fb805",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3173bfb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b996527f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "781778d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hawky\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48f6db87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda:  False\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "086a7b6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\hawky\\AppData\\Local\\Temp\\ipykernel_46956\\671390741.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">7</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'C:\\\\Users\\\\hawky\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_46956\\\\671390741.py'</span>                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">c:\\Users\\hawky\\university\\IA\\final\\capstone-project\\python\\VideoInputParser.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">26</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">parse_video</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 23 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">parse_video</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, video_bytes):                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 24 │   │   </span>video_path = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._write_video_to_temp_file(video_bytes)                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 25 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 26 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>images = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._extract_images_from_video(video_path)                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 27 │   │   </span>parsed_images = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._parse_images(images)                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 28 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 29 │   │   </span>json_transcript = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._video_to_text(video_path)                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">c:\\Users\\hawky\\university\\IA\\final\\capstone-project\\python\\VideoInputParser.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">42</span> in             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_extract_images_from_video</span>                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 39 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> temp.name                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 40 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 41 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_extract_images_from_video</span>(video_path, images_per_second=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0.8</span>):                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 42 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>video = cv2.VideoCapture(video_path)                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 43 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 44 │   │   </span>fps = video.get(cv2.CAP_PROP_FPS)                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 45 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> fps &lt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0.1</span>:                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">error: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">OpenCV</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.6</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span> :<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1</span>: error: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-5</span>:Bad argument<span style=\"font-weight: bold\">)</span> in function <span style=\"color: #008000; text-decoration-color: #008000\">'VideoCapture'</span>\n",
       "&gt; Overload resolution failed:\n",
       "&gt;  - Can't convert object to <span style=\"color: #008000; text-decoration-color: #008000\">'str'</span> for <span style=\"color: #008000; text-decoration-color: #008000\">'filename'</span>\n",
       "&gt;  - <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">VideoCapture</span><span style=\"font-weight: bold\">()</span> missing required argument <span style=\"color: #008000; text-decoration-color: #008000\">'apiPreference'</span> <span style=\"font-weight: bold\">(</span>pos <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
       "&gt;  - Argument <span style=\"color: #008000; text-decoration-color: #008000\">'index'</span> is required to be an integer\n",
       "&gt;  - <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">VideoCapture</span><span style=\"font-weight: bold\">()</span> missing required argument <span style=\"color: #008000; text-decoration-color: #008000\">'apiPreference'</span> <span style=\"font-weight: bold\">(</span>pos <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\hawky\\AppData\\Local\\Temp\\ipykernel_46956\\671390741.py\u001b[0m:\u001b[94m7\u001b[0m in \u001b[92m<module>\u001b[0m                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: \u001b[0m                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m'C:\\\\Users\\\\hawky\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_46956\\\\671390741.py'\u001b[0m                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mc:\\Users\\hawky\\university\\IA\\final\\capstone-project\\python\\VideoInputParser.py\u001b[0m:\u001b[94m26\u001b[0m in \u001b[92mparse_video\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 23 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mparse_video\u001b[0m(\u001b[96mself\u001b[0m, video_bytes):                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 24 \u001b[0m\u001b[2m│   │   \u001b[0mvideo_path = \u001b[96mself\u001b[0m._write_video_to_temp_file(video_bytes)                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 25 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 26 \u001b[2m│   │   \u001b[0mimages = \u001b[96mself\u001b[0m._extract_images_from_video(video_path)                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 27 \u001b[0m\u001b[2m│   │   \u001b[0mparsed_images = \u001b[96mself\u001b[0m._parse_images(images)                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 28 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 29 \u001b[0m\u001b[2m│   │   \u001b[0mjson_transcript = \u001b[96mself\u001b[0m._video_to_text(video_path)                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mc:\\Users\\hawky\\university\\IA\\final\\capstone-project\\python\\VideoInputParser.py\u001b[0m:\u001b[94m42\u001b[0m in             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_extract_images_from_video\u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 39 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m temp.name                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 40 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 41 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_extract_images_from_video\u001b[0m(video_path, images_per_second=\u001b[94m0.8\u001b[0m):                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 42 \u001b[2m│   │   \u001b[0mvideo = cv2.VideoCapture(video_path)                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 43 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 44 \u001b[0m\u001b[2m│   │   \u001b[0mfps = video.get(cv2.CAP_PROP_FPS)                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 45 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m fps < \u001b[94m0.1\u001b[0m:                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91merror: \u001b[0m\u001b[1;35mOpenCV\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m4.6\u001b[0m.\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m :\u001b[1;36m-1\u001b[0m: error: \u001b[1m(\u001b[0m\u001b[1;36m-5\u001b[0m:Bad argument\u001b[1m)\u001b[0m in function \u001b[32m'VideoCapture'\u001b[0m\n",
       "> Overload resolution failed:\n",
       ">  - Can't convert object to \u001b[32m'str'\u001b[0m for \u001b[32m'filename'\u001b[0m\n",
       ">  - \u001b[1;35mVideoCapture\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m missing required argument \u001b[32m'apiPreference'\u001b[0m \u001b[1m(\u001b[0mpos \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n",
       ">  - Argument \u001b[32m'index'\u001b[0m is required to be an integer\n",
       ">  - \u001b[1;35mVideoCapture\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m missing required argument \u001b[32m'apiPreference'\u001b[0m \u001b[1m(\u001b[0mpos \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a7393a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "38aeb5d2c9cda807f795d9978a6093cc9be471233610cf6939db788845adaf22"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
