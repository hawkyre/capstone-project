{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Model,Sequential, load_model,model_from_json\n",
    "from tensorflow.compat.v1.keras.backend import set_session \n",
    "from PIL import Image\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# Importar módulo facial_analysis.py\n",
    "from facial_analysis import FacialImageProcessing\n",
    "\n",
    "from pytorch_grad_cam import GradCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class FacialEmotionRecognition:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        %env CUDA_VISIBLE_DEVICES=0\n",
    "        \n",
    "        # Configuración de la sesión\n",
    "        config = tf.compat.v1.ConfigProto()\n",
    "        config.gpu_options.allow_growth = True\n",
    "        sess=tf.compat.v1.Session(config=config)\n",
    "        set_session(sess)\n",
    "\n",
    "        # Comprobar si hay cuda o si se ha de usar la cpu\n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "        print(\"Cuda: \", self.use_cuda)\n",
    "        self.device = 'cuda' if self.use_cuda else 'cpu'\n",
    "\n",
    "        # Utilización modelo de procesado de la imagen\n",
    "        self.imgProcessing = FacialImageProcessing(False)\n",
    "                        \n",
    "        # El modelo escogido es enet_b2_7.pt, que predice las 7 emociones básicas\n",
    "        NUM_EMOTIONS = 7\n",
    "        self.IMG_SIZE = 260\n",
    "        models_path,_ = os.path.split(os.path.realpath(__file__))\n",
    "        PATH=os.path.join(models_path,'models','affectnet_emotions','enet_b2_7.pt')\n",
    "        self.idx_to_class = {0: 'Anger', 1: 'Disgust', 2: 'Fear', 3: 'Happiness', 4: 'Neutral', 5: 'Sadness', 6: 'Surprise'}\n",
    "\n",
    "        # Transformar la imagen a tensor para hacer inferencia\n",
    "        self.test_transforms = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize((self.IMG_SIZE, self.IMG_SIZE)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                             std=[0.229, 0.224, 0.225])\n",
    "            ]\n",
    "        )\n",
    "        # print(PATH)\n",
    "        self.model = torch.load(PATH,map_location=torch.device(self.device)) # Cargar el modelo en la cpu\n",
    "        self.model = self.model.to(self.device)\n",
    "        # model.eval()\n",
    "        \n",
    "    def FramePrediction(self, frame=None, heat_map=False):\n",
    "        \n",
    "        scores = []\n",
    "        max_score = []\n",
    "        \n",
    "        # Comprobar si hay frame\n",
    "        if frame is not None:\n",
    "            \n",
    "            # Predicción de las caras de la imagen y plot de las mismas junto a sus predicciones\n",
    "            frame_bgr=frame\n",
    "            # plt.figure(figsize=(5, 5))\n",
    "            frame = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)\n",
    "            # plt.axis('off')\n",
    "            # plt.imshow(frame)\n",
    "            bounding_boxes, points = self.imgProcessing.detect_faces(frame)\n",
    "            points = points.T\n",
    "            \n",
    "            cont_faces = 1\n",
    "            \n",
    "            # Comprobar si hay caras\n",
    "            if bounding_boxes.any(): \n",
    "\n",
    "                for bbox,p in zip(bounding_boxes, points):\n",
    "                    box = bbox.astype(np.int)\n",
    "                    x1,y1,x2,y2=box[0:4]    \n",
    "                    face_img=frame[y1:y2,x1:x2,:]\n",
    "\n",
    "                    img_tensor = self.test_transforms(Image.fromarray(face_img))\n",
    "                    img_tensor.unsqueeze_(0)\n",
    "                    scores = self.model(img_tensor.to(self.device))\n",
    "                    scores=scores[0].data.cpu().numpy()\n",
    "                    max_score=self.idx_to_class[np.argmax(scores)]\n",
    "                    \n",
    "                    plt.figure(figsize=(3, 3))\n",
    "                    plt.axis('off')\n",
    "                    plt.imshow(face_img)\n",
    "                    plt.title(max_score)\n",
    "                    print(\"Score cara {}: \".format(cont_faces),scores)\n",
    "                    plt.show()\n",
    "\n",
    "                    cont_faces = cont_faces+1\n",
    "\n",
    "                    # Para ver el mapa de calor\n",
    "                    if heat_map == True:\n",
    "\n",
    "                        # Para ver el mapa de calor (GradCAM), que ayuda a detectar las regiones \n",
    "                        # consideradas importantes por la red neuronal para realizar la predicción\n",
    "\n",
    "                        target_layers = [self.model.blocks[-1][-1]]\n",
    "                        # Construct the CAM object once, and then re-use it on many images:\n",
    "                        cam = GradCAM(model=self.model, target_layers=target_layers, use_cuda=self.use_cuda)\n",
    "\n",
    "                        grayscale_cam = cam(input_tensor=img_tensor)\n",
    "                        grayscale_cam = grayscale_cam[0, :]\n",
    "                        face_img=cv2.resize(face_img,(self.IMG_SIZE, self.IMG_SIZE))\n",
    "                        rgb_img = np.float32(face_img) / 255\n",
    "                        visualization = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)\n",
    "\n",
    "                        plt.figure(figsize=(3, 3))\n",
    "                        plt.axis('off')\n",
    "                        plt.imshow(visualization)\n",
    "                        plt.title(max_score)  \n",
    "                        plt.show()\n",
    "                                      \n",
    "            # Si no hay caras\n",
    "            else: print(\"There is no faces!\")\n",
    "           \n",
    "        # Si no hay imagen (frame)\n",
    "        else: print(\"There is no image!\")\n",
    "            \n",
    "        return scores, max_score            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
